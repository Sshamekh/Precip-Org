{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137de0c4-ae8f-4b7f-9f17-15aeaa33ad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## rotating data in batch while training \n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  layers.experimental.preprocessing.RandomRotation(1,fill_mode= 'wrap',\n",
    "    interpolation='bilinear',\n",
    ")\n",
    "])\n",
    "\n",
    "## create encode \n",
    "encoder_result = encoder_gen((25, 25,2),model_config[\"configs_encoder\"])\n",
    "\n",
    "## create decoder\n",
    "decode_zz = decoder_dense((25, 25,2),model_config[\"config_decoder\"])\n",
    "\n",
    "\n",
    "inputhighres = tf.keras.layers.Input(shape=(25, 25,2))\n",
    "input_rotate = data_augmentation(inputhighres)\n",
    "\n",
    "\n",
    "z = encoder_result.vae_encoder(inputhighres) ## mapping original data to latent space\n",
    "zr = encoder_result.vae_encoder(input_rotate) ## mapping rotated data to latent space\n",
    "\n",
    "hr_reconst= decode_zz(z) ## reconstructing original data from z\n",
    "hr_reconst_r = decode_zz(zr) ## reconstructing original data from zr. It has to be the same as hr_reconst \n",
    "\n",
    "z_clt = tf.keras.layers.Concatenate(axis = -1)([z,inputdense])\n",
    "cloud_cover = clouds_cc(z_clt)\n",
    "\n",
    "\n",
    "\n",
    "vae = tf.keras.Model(inputs=[inputhighres], outputs=[hr_reconst])\n",
    "\n",
    "optimizer = tensorflow.keras.optimizers.Adam(lr=0.0004)\n",
    "callback_lr=LearningRateScheduler(schedule,verbose=1)\n",
    "earlyStopping=tensorflow.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "vae.compile(loss = mse, optimizer = optimizer)\n",
    "\n",
    "\n",
    "# two ways to force rotation invariance: \n",
    "# 1. z and zr should be mapped to the same subspace. So we add a term to loss that force this. \n",
    "RI_loss = K.mean(K.square(z-zr))\n",
    "vae.add_metric(RI_loss,name = 'RI_loss')\n",
    "vae.add_loss(coef*RI_loss)\n",
    "\n",
    "# 2. hr reconst_r should be recoundtucted to non rotated impage, i.e. hr reconst_r = hr reconst. We can add this to loss function\n",
    "# apparently 1 is easier to enforce. Enforcig 2 is compicated as the reconstruction is not that good. \n",
    "#hr_loss = K.mean(K.square(hr_reconst-hr_reconst_r))\n",
    "#vae.add_metric(hr_loss,name = 'RI_loss')\n",
    "#vae.add_loss(coef*hr_loss)\n",
    "\n",
    "\n",
    "hist = vae.fit(\n",
    "        x=[x_train_hr], \n",
    "        y=[x_train_hr], \n",
    "        epochs=100,\n",
    "        batch_size=128,\n",
    "        validation_split = 0.3,\n",
    "        callbacks= [earlyStopping,callback_lr],\n",
    "        shuffle = True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
